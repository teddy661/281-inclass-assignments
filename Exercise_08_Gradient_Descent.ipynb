{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Types of Optimization**\n",
        "\n",
        "In this exercise you will fill in the missing calculations for steepest descent, conjugate gradient descent, and gradient descent.\n",
        "\n",
        "**1) steepest descent**:  calculate direction of negative gradient, step size, and new parameters\n",
        "\n",
        "**2) conjugate gradient descent**: calculate direction of negative gradient, step size, and new parameters (same as for steepest descent)\n",
        "\n",
        "**3) gradient descent**: calculate direction of negative gradient, try different step sizes\n",
        "\n",
        "------\n",
        "**Discussion questions**\n",
        "\n",
        "What is the difference between these three methods?\n",
        "\n",
        "Are they all guaranteed to converge?\n",
        "\n",
        "Which one is likely to be the fastest?\n",
        "\n",
        "Which one will be the most accurate? Why?"
      ],
      "metadata": {
        "id": "h1hSoG1vQoL9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oi0rt6tJQnQV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_error_surface(U, y):\n",
        "  # plot quadratic error surface and steepest descent path\n",
        "  E = np.zeros((100,100))\n",
        "  i = 0\n",
        "  for u2 in np.arange(-5,5,0.1):\n",
        "    j = 0\n",
        "    for u1 in np.arange(-5,5,0.1):\n",
        "      E[i,j] = np.linalg.norm( X@[[u1],[u2]] - y ) # error\n",
        "      j = j + 1\n",
        "    i = i + 1\n",
        "\n",
        "  fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
        "  ax.set(xlim=(-5,5), ylim=(-5,5))\n",
        "  ax.set_aspect('equal', 'box')\n",
        "  plt.grid()\n",
        "  xx,yy = np.meshgrid(np.linspace(-5,5,100), np.linspace(-5,5,100))\n",
        "  plt.contour(xx,yy,E,50,cmap='plasma')\n",
        "  plt.scatter(u[0],u[1],c='r',s=200)\n",
        "  for i in range(len(U) - 1):\n",
        "    plt.plot([U[i][0],U[i+1][0]], [U[i][1],U[i+1][1]],'bo-')"
      ],
      "metadata": {
        "id": "I331ZAamVh1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "n = 20\n",
        "u = 6*np.random.rand(2,1)-3 # slope and intercept\n",
        "x = np.arange(-1,1,0.1).reshape((n,1)) # x-coordinate\n",
        "y = u[0]*x + u[1] # y-coordinate\n",
        "X = np.hstack((x, np.ones((n,1))))\n",
        "\n",
        "# quadratic form\n",
        "A = X.T @ X\n",
        "b = X.T @ y"
      ],
      "metadata": {
        "id": "-xAL1kHKWY-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# steepest descent\n",
        "ui = 10*np.random.rand(2,1)-5 # random starting condition\n",
        "U = [ui]\n",
        "\n",
        "while( True ):\n",
        "  ri = ?? # TODO: calculate direction of negative gradient\n",
        "  ai = ?? # TODO: calculate step size\n",
        "  uj = ?? # TODO: calculate new parameters\n",
        "\n",
        "  U.append(uj)\n",
        "  if( np.linalg.norm(ui-uj) < 1e-3 ):\n",
        "    break\n",
        "  ui = uj\n",
        "\n",
        "plot_error_surface(U, y)"
      ],
      "metadata": {
        "id": "LoIy8EzGRoPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# conjugate gradient descent\n",
        "ui = 10*np.random.rand(2,1)-5 # random starting condition\n",
        "di = b - A@ui # direction of negative gradient\n",
        "ri = di # initial direction\n",
        "U = [ui]\n",
        "\n",
        "while( True ):\n",
        "  ai = ?? # TODO: calculate step size\n",
        "  uj = ?? # TODO: calculate new params\n",
        "  rj = ?? # TODO: calculate new direction\n",
        "  bj = (rj.T @ rj) / (ri.T @ ri)\n",
        "  dj = rj + bj*di\n",
        "\n",
        "  U.append(uj)\n",
        "  if( np.linalg.norm(ui-uj) < 1e-3 ):\n",
        "    break\n",
        "  ui = uj\n",
        "  ri = rj\n",
        "  di = dj\n",
        "\n",
        "plot_error_surface(U, y)"
      ],
      "metadata": {
        "id": "QmelF80vWDpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# gradient descent\n",
        "ui = 10*np.random.rand(2,1)-5\n",
        "ai = ?? # TODO: try different values for step size\n",
        "U = [ui]\n",
        "\n",
        "while( True ):\n",
        "  ri = ?? # TODO: calculate gradient direction\n",
        "  uj = ui - ai*ri # update\n",
        "  U.append(uj)\n",
        "  if( np.linalg.norm(ui-uj) < 1e-3 ):\n",
        "    break\n",
        "  ui = uj\n",
        "\n",
        "plot_error_surface(U, y)"
      ],
      "metadata": {
        "id": "oMluG0XgWmWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dv7v3oo3YuLz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}